{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c0a3b-0243-4a52-a068-296758589bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "\n",
    "#demucs : https://github.com/facebookresearch/demucs\n",
    "!pip install demucs\n",
    "\n",
    "#TTS : https://github.com/coqui-ai/TTS\n",
    "!pip install TTS\n",
    "\n",
    "#srt : https://github.com/cdown/srt\n",
    "!pip install srt\n",
    "\n",
    "#Others\n",
    "!pip install ipython\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d457d5ba-2b73-483a-a555-9b914e451f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git clone https://github.com/machinewrapped/gpt-subtrans.git ../gpt-subtrans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '../gpt-subtrans'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch GPT translator repo\n",
    "command = f'git clone https://github.com/machinewrapped/gpt-subtrans.git ../gpt-subtrans'\n",
    "print(command)\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f67468c-27fc-4f06-b2fc-386ca38c97ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TTS.utils.manage.ModelManager object at 0x7f95ca989a50>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import  whisper\n",
    "from tqdm import trange\n",
    "from moviepy.editor import *\n",
    "import demucs.separate\n",
    "from TTS.api import TTS\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import srt\n",
    "import gc\n",
    "# Get device\n",
    "import IPython.display as ipd\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpt_subtrans_path=\"../gpt-subtrans/gpt-subtrans.py\"\n",
    "# List available ðŸ¸TTS models\n",
    "print(TTS().list_models())\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "def merge_clips(translated_clips,background_track,output_audio_track):\n",
    "    translated_audio = CompositeAudioClip(translated_clips)\n",
    "    translated_audio.clips.append(AudioFileClip(background_track))\n",
    "    translated_audio.fps=16000\n",
    "    translated_audio.write_audiofile(output_audio_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60a16f3-5838-42ed-b950-1c691d672313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The filename and extension of the original video\n",
    "# Try a short video for the first job (less than 2 min), some of the following steps will take a lot of time.\n",
    "filename = 'hell_s_kitchen'\n",
    "file_extension = 'mp4'\n",
    "\n",
    "# source/target code list : https://github.com/openai/whisper/blob/ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab/whisper/tokenizer.py#L10\n",
    "source_language_code = 'en'\n",
    "# source_language_code = 'zh'\n",
    "# source_language_code = 'es'\n",
    "\n",
    "# Target: 16 language supported\n",
    "# code used in tts : run `tts.languages` after the tts initialized\n",
    "# code used in ffmpeg :https://trac.ffmpeg.org/wiki/Map#Specificlanguage\n",
    "\n",
    "# Target Chinese\n",
    "# target_language = 'Simplified Chinese'\n",
    "# target_language_code = 'zh'\n",
    "# target_language_tts_code = 'zh-cn'\n",
    "# target_track_in_ffmpeg = 'zho'\n",
    "\n",
    "\n",
    "\n",
    "# Target Spanish\n",
    "target_language = 'Spanish'\n",
    "target_language_code = 'es'\n",
    "target_language_tts_code = 'es'\n",
    "target_track_in_ffmpeg = 'spa'\n",
    "\n",
    "# target_language = 'English'\n",
    "# target_language_code = 'en'\n",
    "# target_language_tts_code = 'en'\n",
    "# target_track_in_ffmpeg = 'eng'\n",
    "\n",
    "temp = \"../temp/\"\n",
    "input = \"../input/\"\n",
    "\n",
    "# inputs\n",
    "full_filename = f'{filename}.{file_extension}'\n",
    "input_path = f'../input/{full_filename}'\n",
    "\n",
    "# temporary files\n",
    "input_video_path = f'{temp}{filename}_video.mp4'\n",
    "input_audio_path = f'{temp}{filename}_audio.mp3'\n",
    "audio_cuts_path = f\"{temp}cuts/\"\n",
    "demucs_output_vocal=f\"{temp}mdx_extra/{filename}_audio/vocals.mp3\"\n",
    "demucs_output_background=f\"{temp}mdx_extra/{filename}_audio/no_vocals.mp3\"\n",
    "\n",
    "# outputs\n",
    "output = f\"../output/{filename}\"\n",
    "output_original_srt_path = f'{output}/subtitle_{source_language_code}.srt'\n",
    "output_translated_by_gpt_srt_path = f'{output}/subtitle_{target_language_code}_gpt.srt'\n",
    "output_translated_by_s2s_srt_path = f'{output}/subtitle_{target_language_code}_s2s.srt'\n",
    "output_audio_s2s= f'{output}/audio_{target_language_code}_s2s.mp3'\n",
    "output_audio_tts= f'{output}/audio_{target_language_code}_tts.mp3'\n",
    "output_final_video= f'{output}/final_video.mp4'\n",
    "output_final_tts_video= f'{output}/{filename}_tts_{target_language_code}.mp4'\n",
    "output_final_s2s_video= f'{output}/{filename}_s2s_{target_language_code}.mp4'\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.isdir(output):\n",
    "    os.makedirs(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1a26e-077c-4f72-9f60-300c889ee9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into video and audio track.\n",
    "command = f'ffmpeg -i \"{input_path}\" -y -vcodec copy  -c:a copy -an \"{input_video_path}\" -vn \"{input_audio_path}\"'\n",
    "print(command)\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b4e21-72bf-4ca5-8440-6c7f6e52c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio track into vocal and no_vocal(background) audio\n",
    "demucs.separate.main([\"--mp3\", \"--two-stems\", \"vocals\", \"-n\", \"mdx_extra\",\"-o\" ,temp, input_audio_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f863c7f-a502-46c9-8289-dcd71a487f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect subtitles from vocal audio.\n",
    "model=None\n",
    "clear_memory()\n",
    "model = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d036cbc-8f49-48c1-8167-5023e5130dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use demucs_output_vocal or input_audio_path?\n",
    "# You should check the output since it transcribes wrong results!!!\n",
    "# no_speech_threshold=0.3,logprob_threshold=-0.5,\n",
    "clear_memory()\n",
    "result = model.transcribe(demucs_output_vocal,verbose=True,condition_on_previous_text=False,no_speech_threshold=0.5,word_timestamps=True,language=source_language_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c1ba4-7afa-447d-9597-338fd74fb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save srt file.\n",
    "segments=result['segments']\n",
    "subtitles = []\n",
    "audio_vacal = AudioFileClip(demucs_output_vocal)\n",
    "duration = audio_vacal.duration\n",
    "audio_vacal.close()\n",
    "count = 0\n",
    "for i in trange(len(segments)): \n",
    "    \n",
    "    segment = segments[i]\n",
    "    start = segment['start']\n",
    "    end = segment['end']\n",
    "    if start>duration:\n",
    "        break\n",
    "    if segment['no_speech_prob']>0.8:\n",
    "        continue\n",
    "    end = min(end,duration)\n",
    "\n",
    "    if start==end or len(segment['text'])==0:\n",
    "        # content = segment['text']\n",
    "        # print(segment['id'])\n",
    "        # print(f'start:{start} end:{start} content:{content}')\n",
    "        continue\n",
    "    count=count+1\n",
    "    subtitle = srt.Subtitle(index=count,start=timedelta(seconds=segment['start']),end=timedelta(seconds=segment['end']),content=segment['text'])\n",
    "    subtitles.append(subtitle)\n",
    "subtitle_original = srt.compose(subtitles)\n",
    "srt_file = open(output_original_srt_path,\"w\")\n",
    "srt_file.write(subtitle_original)\n",
    "srt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec283c9-d89c-4c6b-90c1-19b5f31ed6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# !!!!!!!! Fill the API key !!!!!!!!!!\n",
    "# translate subtitle with ChatGpt\n",
    "# It'll take a long time(more than 30min for 900 sentences) because of the 'Rate limits' on the OpenAI free trial.\n",
    "# You can change the limit if you have Credit Grants.\n",
    "# https://platform.openai.com/account/limits\n",
    "# more detail in https://github.com/machinewrapped/gpt-subtrans \n",
    "# About 0.2$ for a subtitle file with 900 sentences.\n",
    "key = 'Put your openai key here(https://platform.openai.com/api-keys)'\n",
    "gpt_model = 'gpt-3.5-turbo-16k'\n",
    "os.environ[\"GPT_MODEL\"] = gpt_model\n",
    "limit = 3 # If you have a higher rate limit, use a larger number to speed up this process\n",
    "if os.path.isfile(output_translated_by_gpt_srt_path):\n",
    "    print(\"srt has been translated\")\n",
    "else:\n",
    "    command = f'python \"{gpt_subtrans_path}\" \"{output_original_srt_path}\" -k {key}  --target_language \"{target_language}\" -o \"{output_translated_by_gpt_srt_path}\" -r {limit}'\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c0101-5716-4532-8d99-ef3001c5a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init TTS\n",
    "if 'tts'  not in vars() or tts is None:\n",
    "    tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349cd822-01c3-46cd-96cb-18dc9663a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if os.path.isdir(audio_cuts_path):\n",
    "    shutil.rmtree(audio_cuts_path)\n",
    "if not os.path.isdir(audio_cuts_path):\n",
    "    os.makedirs(audio_cuts_path)\n",
    "    \n",
    "file = open(output_original_srt_path,'r')\n",
    "subtitles_original = srt.parse(file.read())\n",
    "subtitles_original = list(subtitles_original)\n",
    "file.close()\n",
    "\n",
    "# read translated_srt\n",
    "file = open(output_translated_by_gpt_srt_path,'r')\n",
    "subtitles_zh = srt.parse(file.read())\n",
    "subtitles_zh = list(subtitles_zh)\n",
    "file.close()\n",
    "\n",
    "tts_speed = None\n",
    "s2s_clips = []\n",
    "tts_clips = []\n",
    "subtitles_s2s=[]\n",
    "previous_end = 0\n",
    "audio_vacal = AudioFileClip(demucs_output_vocal)\n",
    "duration=audio_vacal.duration\n",
    "audio_vacal.close()\n",
    "for i in trange(len(subtitles_zh)): \n",
    "    segment = subtitles_zh[i]\n",
    "    segment_original=subtitles_original[i]\n",
    "    if i+1<len(subtitles_zh):\n",
    "        next_segment=subtitles_zh[i+1]\n",
    "        next_start =  next_segment.start.total_seconds()\n",
    "    else:\n",
    "        next_start = duration\n",
    "    speaker_wav = audio_cuts_path+f\"{i}.wav\"\n",
    "    start =  segment.start.total_seconds()\n",
    "    \n",
    "    end = segment.end.total_seconds()\n",
    "    print(f'======\\nstart:{start} end:{end} \\n{segment_original.content} \\n{segment.content}')\n",
    "    audio_vacal = AudioFileClip(demucs_output_vocal)\n",
    "    audio_clip = audio_vacal.subclip(start,end)\n",
    "    audio_clip.write_audiofile(speaker_wav,verbose=False,logger=None)\n",
    "    audio_clip.close()\n",
    "    audio_vacal.close()\n",
    "    \n",
    "    content = subtitles_zh[i].content\n",
    "    out_wav_tts = audio_cuts_path+f\"{i}_zh_tts.wav\"\n",
    "    out_wav_tts_fixed = audio_cuts_path+f\"{i}_zh_tts_fixed.wav\"\n",
    "\n",
    "    try:\n",
    "        expect_duration = end-start\n",
    "        count = 0\n",
    "        last_duraion = 1000000\n",
    "        # Because sometimes the TTS creates audio clips that are quite long, it may be a bug of TTS\n",
    "        # Try 3 times if duration < expect_duration * 1.8, and pick the shortest one.\n",
    "        while count<3:\n",
    "            out_wav_tts_temp = audio_cuts_path+f\"{i}_zh_tts_temp.wav\"\n",
    "            tts.tts_to_file(text=content, speaker_wav=speaker_wav,speed=tts_speed, language=target_language_tts_code, file_path=out_wav_tts_temp)\n",
    "            tts_audio_clip = AudioFileClip(out_wav_tts_temp)\n",
    "            duration = tts_audio_clip.duration\n",
    "            tts_audio_clip.close()\n",
    "            # Pick the shortest one.\n",
    "            if duration < last_duraion:\n",
    "                last_duraion = duration\n",
    "                shutil.copyfile(out_wav_tts_temp, out_wav_tts)\n",
    "            os.remove(out_wav_tts_temp)\n",
    "            if duration < expect_duration * 1.8:\n",
    "                print(f'accept expect_duration:{expect_duration} duration:{duration} , time:{count}')\n",
    "                break\n",
    "            else:\n",
    "                count = count+1\n",
    "                print(f'retry expect_duration:{expect_duration} duration:{duration} , time:{count}')\n",
    "                continue\n",
    "\n",
    "        # Adjust the audio speed.\n",
    "        factor = 1.0\n",
    "        fixed_start = start\n",
    "        diff = 0\n",
    "        if fixed_start<previous_end:\n",
    "            diff = previous_end-fixed_start\n",
    "            fixed_start = previous_end\n",
    "        if duration>expect_duration:\n",
    "            expect_duration-=diff\n",
    "            if expect_duration<=0:\n",
    "                factor = 1.8\n",
    "            else:\n",
    "                factor = max(duration/expect_duration,factor)\n",
    "                factor = min(factor,1.8)\n",
    "        \n",
    "        command = f'ffmpeg -i \"{out_wav_tts}\" -af atempo={factor} -hide_banner -loglevel error -y {out_wav_tts_fixed}'\n",
    "        os.system(command)\n",
    "        tts_audio_clip = AudioFileClip(out_wav_tts_fixed)\n",
    "        duration = tts_audio_clip.duration\n",
    "        temp = previous_end\n",
    "        previous_end = fixed_start+duration\n",
    "        tts_audio_clip=tts_audio_clip.set_start(fixed_start)\n",
    "        tts_clips.append(tts_audio_clip)\n",
    "        print(f'factor:{factor} previous_end:{temp} , fixed_start:{fixed_start} fixed_end:{previous_end}')\n",
    "\n",
    "        # Debug: show original audio, translated audio and adjusted speed audio, will slow down this process\n",
    "        # IPython.display.display(ipd.Audio(speaker_wav,autoplay=False) )\n",
    "        # IPython.display.display(ipd.Audio(out_wav_tts,autoplay=False) )\n",
    "        # IPython.display.display(ipd.Audio(out_wav_tts_fixed,autoplay=False) )\n",
    "    except RuntimeError as e:\n",
    "        print(\"error in tts\")\n",
    "        print(e)\n",
    "    except Exception as error:\n",
    "        print(\"error in tts\")\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ac31a-063f-4528-b28b-41e71203de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge translated audio clips and background audio.\n",
    "merge_clips(tts_clips,demucs_output_background,output_audio_tts)\n",
    "for clip in tts_clips:\n",
    "    clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741d6eb-3445-4e32-bc81-2b2ccd019f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator the final video with the original video track, translated audio track and translated subtitle.\n",
    "# Find the video in 'output' folder.\n",
    "command = f'ffmpeg -i \"{input_video_path}\" -i \"{output_audio_tts}\" -i \"{output_translated_by_gpt_srt_path}\" -c:v copy -c:a copy -c:s mov_text -map 0 -map 1 -map 2 -metadata:s:s:0 language={target_track_in_ffmpeg}  -movflags +faststart -y \"{output_final_tts_video}\"'\n",
    "print(command)\n",
    "os.system(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
